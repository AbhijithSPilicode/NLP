{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "22e93f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT (Bidirectional Encoder Representations from Transformers) is a recent paper published by researchers at Google AI Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "daf4ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is designed to understand context and meaning in text by learning bidirectional representations of words:Transfotmers\n",
    "#This pre-trained model can then be fine-tuned for specific NLP tasks such as text classification, question answering,named entity recognition and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5585d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6c219377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cd1d9a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "63ea72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question and passage\n",
    "question = \"Who is the most successful captain in IPL?\"\n",
    "passage = \"Dhoni led Chennai Super Kings to five IPL wins in 2010, 2011, 2018, 2021 and 2023.Dhoni has also shown incredible leadership potential.Dhoni captained the CSK and won the championship. CSK topped the table both in IPL 2022 and IPL 2023 and played in the final as well under his captaincy.There is no doubt that Dhoni is the most successful captain in the history of the IPL.But rohit also done his part well as captain for MI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0c27b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2040,  2003,  1996,  2087,  3144,  2952,  1999, 12997,  2140,\n",
       "          1029,   102, 28144, 10698,  2419, 12249,  3565,  5465,  2000,  2274,\n",
       "         12997,  2140,  5222,  1999,  2230,  1010,  2249,  1010,  2760,  1010,\n",
       "         25682,  1998, 16798,  2509,  1012, 28144, 10698,  2038,  2036,  3491,\n",
       "          9788,  4105,  4022,  1012, 28144, 10698, 16041,  1996, 20116,  2243,\n",
       "          1998,  2180,  1996,  2528,  1012, 20116,  2243,  9370,  1996,  2795,\n",
       "          2119,  1999, 12997,  2140, 16798,  2475,  1998, 12997,  2140, 16798,\n",
       "          2509,  1998,  2209,  1999,  1996,  2345,  2004,  2092,  2104,  2010,\n",
       "          2952,  5666,  1012,  2045,  2003,  2053,  4797,  2008, 28144, 10698,\n",
       "          2003,  1996,  2087,  3144,  2952,  1999,  1996,  2381,  1997,  1996,\n",
       "         12997,  2140,  1012,  2021, 20996, 16584,  2036,  2589,  2010,  2112,\n",
       "          2092,  2004,  2952,  2005,  2771,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and encode the input\n",
    "#encode_plus tokenize and then the tokenized text is then encoded into numerical representations that the model can understand.\n",
    "inputs = tokenizer.encode_plus(question, passage, add_special_tokens=True, return_tensors=\"pt\")\n",
    "#encode plus takes the question and passage as input and returns a dictionary containing the tokenized and encoded input suitable for BERT.\n",
    "#add_special_token:This parameter indicates that special tokens like [CLS] and [SEP] should be added to the tokenized input. \n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "617645f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5741, -0.1025,  0.2322,  0.1602, -0.1531,  0.0014,  0.3765, -0.1896,\n",
       "          0.2412,  0.5027, -0.3914, -0.0520,  0.4166, -0.0074, -0.0341,  0.3344,\n",
       "          0.2804,  0.2338,  0.0981, -0.2576, -0.1622,  0.1194, -0.0662, -0.1954,\n",
       "         -0.2435, -0.2684, -0.1996, -0.1824, -0.0865, -0.1460,  0.0512,  0.1210,\n",
       "          0.2171,  0.1470,  0.0888,  0.4725,  0.0739, -0.0486, -0.1618, -0.0679,\n",
       "         -0.0265,  0.1423,  0.0637,  0.1052,  0.5039,  0.1236,  0.0060,  0.1077,\n",
       "          0.6143,  0.3075, -0.3299, -0.1688, -0.1268,  0.0938,  0.0894,  0.5550,\n",
       "          0.3833, -0.1737, -0.0275, -0.0032, -0.0236, -0.0119,  0.0641,  0.3056,\n",
       "          0.2881,  0.2800,  0.0840,  0.0863,  0.3783,  0.3051,  0.6481, -0.0672,\n",
       "          0.0195,  0.0735,  0.0246,  0.1771, -0.2826, -0.1142,  0.0158,  0.4508,\n",
       "          0.2065,  0.0472,  0.1010, -0.0206, -0.2354, -0.1084,  0.0369,  0.2270,\n",
       "          0.5939,  0.2891,  0.2356,  0.1227, -0.2665, -0.1038,  0.2714, -0.3159,\n",
       "         -0.0719,  0.0406,  0.2993,  0.0741,  0.0387,  0.3466, -0.0015, -0.0692,\n",
       "          0.3041,  0.1827, -0.3820, -0.4583,  0.0201, -0.7502, -0.4595, -0.1630,\n",
       "         -0.0356, -0.0435,  0.6106,  0.0839]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions\n",
    "#logits are raw scores that represent the model's confidence for each possible class or label.\n",
    "start_logits, end_logits = model(**inputs).values() #This line passes the dictionary of inputs to the BERT model\n",
    "end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f1200f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16)\n",
      "tensor(71)\n"
     ]
    }
   ],
   "source": [
    "# Find the start and end positions of the answer span\n",
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "#In the context of question answering, this index corresponds to the most likely position where the answer span begins within the passage.\n",
    "print(start_idx)\n",
    "print(end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ebbd0402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'super kings to five ipl wins in 2010 , 2011 , 2018 , 2021 and 2023 . dhoni has also shown incredible leadership potential . dhoni captained the csk and won the championship . csk topped the table both in ipl 2022 and ipl 2023'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the answer span\n",
    "answer_span = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_idx:end_idx]))\n",
    "answer_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "779c3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[CLS] is the classification token, and [SEP] separates the question from the passage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "984ddd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ca269629",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7f5f0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(text):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(labels))\n",
    "\n",
    "    # Tokenize and encode the input\n",
    "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Get predictions\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "    # Get predicted label\n",
    "    predicted_label = labels[torch.argmax(logits).item()]\n",
    "\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9086fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "text = \"I really enjoyed the movie. The acting was great and the plot was mindblowing.The climax portion was outstanding.\"\n",
    "# Classify the sentiment\n",
    "sentiment = classify_sentiment(text)\n",
    "print(\"Predicted Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c18ce52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e24b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
