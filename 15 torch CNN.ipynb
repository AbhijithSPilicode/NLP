{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d07d199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch is an open-source machine learning library primarily used for deep learning tasks developed by facebook.\n",
    "#PyTorch uses immediate execution (i.e., eager mode), it is said to be easier to use than TensorFlow when it comes to debugging.\n",
    "#simplifies the creation of artificial neural network models\n",
    "import torch\n",
    "import torch.nn as nn #neural network\n",
    "import torch.optim as optim #optimizer\n",
    "import torchvision #for image processing purposes\n",
    "import torchvision.transforms as transforms #to help in data preprocessing, augmentation, and normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "989b750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#RGB channel\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) #dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57e04021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):  #for layers  #5 layers\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)#3 channel,16 node,(3,3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) #A fully connected layer multiplies the input by a weight matrix and then adds a bias vector.\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128) #fully connected layers\n",
    "        self.fc2 = nn.Linear(128, 10) #10 classes \n",
    "\n",
    "    def forward(self, x): #for activation function\n",
    "        x = self.pool(torch.relu(self.conv1(x))) #activation layer for convolution layer 1\n",
    "        x = self.pool(torch.relu(self.conv2(x))) \n",
    "        x = x.view(-1, 32 * 8 * 8)  # Flatten the feature maps\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d78e4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN, loss function, and optimizer\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #optimizer stochastic gradient descend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aeb6be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023116533756256104\n",
      "0.004607182502746582\n",
      "0.0069103498458862305\n",
      "0.009203576803207398\n",
      "0.01150598120689392\n",
      "0.013825290679931641\n",
      "0.016128637313842772\n",
      "0.018439176082611083\n",
      "0.02074725103378296\n",
      "0.023061453342437744\n",
      "0.025380791425704957\n",
      "0.0276958327293396\n",
      "0.029994279623031615\n",
      "0.03229910469055176\n",
      "0.03459835910797119\n",
      "0.03689684653282165\n",
      "0.03920018529891968\n",
      "0.04149807381629944\n",
      "0.04380958771705627\n",
      "0.04612218189239502\n",
      "0.04841706728935242\n",
      "0.0507288920879364\n",
      "0.05303731083869934\n",
      "0.055334972858428956\n",
      "0.057629568338394166\n",
      "0.05992893314361572\n",
      "0.062231274843215945\n",
      "0.06452600359916687\n",
      "0.06682570934295655\n",
      "0.06912697863578797\n",
      "0.07143043637275696\n",
      "0.07373040580749511\n",
      "0.07602066612243652\n",
      "0.07832038974761962\n",
      "0.0806230251789093\n",
      "0.08292125606536865\n",
      "0.08522230434417724\n",
      "0.08751948380470276\n",
      "0.08981788206100463\n",
      "0.0921133484840393\n",
      "0.09441046404838561\n",
      "0.09671737909317017\n",
      "0.09901193141937256\n",
      "0.1013071813583374\n",
      "0.10359099102020264\n",
      "0.10588830232620239\n",
      "0.10818297672271729\n",
      "0.11048052096366882\n",
      "0.1127772479057312\n",
      "0.1150736801624298\n",
      "0.11737338161468505\n",
      "0.11966527915000916\n",
      "0.12196120834350586\n",
      "0.12425064778327942\n",
      "0.1265470666885376\n",
      "0.12884592032432557\n",
      "0.13114761114120482\n",
      "0.13343508243560792\n",
      "0.13573016595840454\n",
      "0.1380168948173523\n",
      "0.14030833554267882\n",
      "0.1426056592464447\n",
      "0.1448953311443329\n",
      "0.1471889283657074\n",
      "0.14947329545021057\n",
      "0.1517682991027832\n",
      "0.15405638003349303\n",
      "0.1563392117023468\n",
      "0.1586231942176819\n",
      "0.16091489744186402\n",
      "0.16320414543151857\n",
      "0.16548987674713134\n",
      "0.16777795481681823\n",
      "0.17005473709106445\n",
      "0.17235006284713744\n",
      "0.17464180612564087\n",
      "0.17693153405189513\n",
      "0.17923193430900575\n",
      "0.1815243158340454\n",
      "0.18380853199958802\n",
      "0.1860949990749359\n",
      "0.18837730264663696\n",
      "0.19065579986572265\n",
      "0.19294243121147156\n",
      "0.19522385621070862\n",
      "0.19750374555587769\n",
      "0.19978125143051148\n",
      "0.20207187724113465\n",
      "0.20436529731750488\n",
      "0.2066603789329529\n",
      "0.20895524740219115\n",
      "0.2112378969192505\n",
      "0.21351486921310425\n",
      "0.21579224348068238\n",
      "0.21807804822921753\n",
      "0.2203658742904663\n",
      "0.22264428782463075\n",
      "0.22492707896232605\n",
      "0.2272141032218933\n",
      "0.2295059404373169\n",
      "0.2317894730567932\n",
      "0.2340682234764099\n",
      "0.23634921979904175\n",
      "0.23863238048553467\n",
      "0.2409110300540924\n",
      "0.24319272446632384\n",
      "0.24548569226264955\n",
      "0.24776813864707947\n",
      "0.2500553617477417\n",
      "0.25234729981422427\n",
      "0.25462700343132016\n",
      "0.25690939807891844\n",
      "0.2591871337890625\n",
      "0.2614591519832611\n",
      "0.26374180483818055\n",
      "0.26602647042274474\n",
      "0.2683090512752533\n",
      "0.2705816526412964\n",
      "0.27286058735847474\n",
      "0.27513242745399474\n",
      "0.2773995242118835\n",
      "0.27967652010917665\n",
      "0.28195627403259277\n",
      "0.28423617863655093\n",
      "0.28651153135299684\n",
      "0.2887787749767303\n",
      "0.2910637276172638\n",
      "0.2933390235900879\n",
      "0.2956205017566681\n",
      "0.2978912136554718\n",
      "0.3001585199832916\n",
      "0.3024275043010712\n",
      "0.30470012497901916\n",
      "0.30697914600372317\n",
      "0.30924728178977967\n",
      "0.3115087866783142\n",
      "0.31379586839675905\n",
      "0.3160561547279358\n",
      "0.31833689975738527\n",
      "0.3205999948978424\n",
      "0.32286936736106875\n",
      "0.3251360831260681\n",
      "0.32741393661499024\n",
      "0.3296755907535553\n",
      "0.3319527266025543\n",
      "0.33422660613059996\n",
      "0.33649270224571226\n",
      "0.33875417828559873\n",
      "0.34101080942153933\n",
      "0.34327671337127685\n",
      "0.34554001498222353\n",
      "0.34781405234336854\n",
      "0.3500665655136108\n",
      "0.3523354198932648\n",
      "0.35461273860931397\n",
      "0.35686888766288755\n",
      "0.35914155769348144\n",
      "0.3614044530391693\n",
      "0.36366869616508485\n",
      "0.36592996573448183\n",
      "0.3681910717487335\n",
      "0.37045523715019224\n",
      "0.3727293448448181\n",
      "0.37499239134788515\n",
      "0.37725643801689146\n",
      "0.37952302384376524\n",
      "0.38178766536712644\n",
      "0.3840601522922516\n",
      "0.38631421089172363\n",
      "0.3885630872249603\n",
      "0.3908186089992523\n",
      "0.3930951254367828\n",
      "0.3953530912399292\n",
      "0.397588666677475\n",
      "0.3998248691558838\n",
      "0.40208015060424807\n",
      "0.40434736108779906\n",
      "0.406622056722641\n",
      "0.40887282514572143\n",
      "0.41111942410469055\n",
      "0.413382018327713\n",
      "0.41564783072471617\n",
      "0.41788476729393004\n",
      "0.42012807631492616\n",
      "0.422390917301178\n",
      "0.4246772892475128\n",
      "0.4269164185523987\n",
      "0.4291710810661316\n",
      "0.4314295117855072\n",
      "0.4336829218864441\n",
      "0.4359144380092621\n",
      "0.4381578595638275\n",
      "0.44040964198112487\n",
      "0.44267703986167906\n",
      "0.4449021282196045\n",
      "0.44715179538726807\n",
      "0.4493938217163086\n",
      "0.45164573764801025\n",
      "0.4539231386184692\n",
      "0.45616103053092955\n",
      "0.45840897703170774\n",
      "0.46065125370025634\n",
      "0.4628975548744202\n",
      "0.46511260175704955\n",
      "0.4673429408073425\n",
      "0.46959286189079286\n",
      "0.47183927917480467\n",
      "0.47407133388519285\n",
      "0.4762992758750916\n",
      "0.4785161163806915\n",
      "0.48075461864471436\n",
      "0.48298037934303284\n",
      "0.4852306673526764\n",
      "0.4874486863613129\n",
      "0.4897191061973572\n",
      "0.49192652010917665\n",
      "0.49417594718933106\n",
      "0.496405490398407\n",
      "0.49860503363609315\n",
      "0.5008552987575531\n",
      "0.5030703358650207\n",
      "0.5052941169738769\n",
      "0.5075060410499572\n",
      "0.5097594466209412\n",
      "0.5119868543148041\n",
      "0.5142036526203155\n",
      "0.5164355766773224\n",
      "0.518656054019928\n",
      "0.5208685584068299\n",
      "0.5231250987052918\n",
      "0.5253309919834137\n",
      "0.527566465139389\n",
      "0.5298033740520477\n",
      "0.5320403633117676\n",
      "0.534273656129837\n",
      "0.5364546680450439\n",
      "0.5386535468101501\n",
      "0.5408807623386384\n",
      "0.5431067519187928\n",
      "0.5453327083587647\n",
      "0.5475509934425354\n",
      "0.5497293224334717\n",
      "0.5519514441490173\n",
      "0.5541428914070129\n",
      "0.5563701188564301\n",
      "0.5585860767364502\n",
      "0.560826071023941\n",
      "0.5630676412582397\n",
      "0.5652704541683197\n",
      "0.5674938366413117\n",
      "0.5697041053771973\n",
      "0.5718949637413024\n",
      "0.5741295962333679\n",
      "0.5763710706233979\n",
      "0.5785667524337769\n",
      "0.5807785036563873\n",
      "0.5829944643974304\n",
      "0.5851873419284821\n",
      "0.5873939549922943\n",
      "0.5896032269001007\n",
      "0.5918493435382843\n",
      "0.5940544619560242\n",
      "0.5962285220623016\n",
      "0.5984066443443299\n",
      "0.6006612102985383\n",
      "0.6028903837203979\n",
      "0.6050583083629608\n",
      "0.6072616443634034\n",
      "0.6094354221820831\n",
      "0.6115747632980346\n",
      "0.6137646787166595\n",
      "0.6159481394290924\n",
      "0.6181379208564758\n",
      "0.6203248524665832\n",
      "0.6225190804004669\n",
      "0.6246726222038269\n",
      "0.6268623533248902\n",
      "0.6290774569511414\n",
      "0.6312696132659912\n",
      "0.6334502923488617\n",
      "0.6356340119838715\n",
      "0.6377811620235443\n",
      "0.6399766895771026\n",
      "0.6421162738800049\n",
      "0.6442708051204682\n",
      "0.6463956134319305\n",
      "0.6485785946846009\n",
      "0.650748997926712\n",
      "0.6529493556022644\n",
      "0.6551111147403718\n",
      "0.657273154258728\n",
      "0.6594788599014282\n",
      "0.6616359360218048\n",
      "0.6637752075195312\n",
      "0.6659010362625122\n",
      "0.6680855703353882\n",
      "0.6702218577861786\n",
      "0.6723943417072296\n",
      "0.6745022335052491\n",
      "0.6766320295333862\n",
      "0.6787780344486236\n",
      "0.6809608321189881\n",
      "0.6831904799938202\n",
      "0.6853672132492066\n",
      "0.6874908945560455\n",
      "0.6896467399597168\n",
      "0.6918347301483154\n",
      "0.693961941242218\n",
      "0.6961361372470856\n",
      "0.6983122892379761\n",
      "0.7004049024581909\n",
      "0.7025565590858459\n",
      "0.7047456929683685\n",
      "0.7068538322448731\n",
      "0.7089713885784149\n",
      "0.7110430886745452\n",
      "0.7132114970684051\n",
      "0.7154047966003418\n",
      "0.7174926426410675\n",
      "0.7196748611927033\n",
      "0.7218071916103364\n",
      "0.7239871945381164\n",
      "0.7261246967315674\n",
      "0.7283017411231995\n",
      "0.7304564747810364\n",
      "0.7325089421272278\n",
      "0.7346365344524384\n",
      "0.7368063147068024\n",
      "0.738958969116211\n",
      "0.741146874666214\n",
      "0.7433192086219788\n",
      "0.7453739867210388\n",
      "0.7475291619300842\n",
      "0.7497647287845611\n",
      "0.7519355003833771\n",
      "0.7540727167129516\n",
      "0.7561936902999878\n",
      "0.7583068296909332\n",
      "0.7603938620090485\n",
      "0.7624543492794037\n",
      "0.7645740087032318\n",
      "0.7666852655410766\n",
      "0.768808090209961\n",
      "0.7708634514808654\n",
      "0.7729844605922699\n",
      "0.7751088464260101\n",
      "0.7772186114788056\n",
      "0.7793920204639435\n",
      "0.7814849600791931\n",
      "0.7836038234233856\n",
      "0.7857851917743683\n",
      "0.7879060845375061\n",
      "0.7899447956085205\n",
      "0.7921006441116333\n",
      "0.7942971546649933\n",
      "0.7964290609359741\n",
      "0.7986367814540863\n",
      "0.8007378227710724\n",
      "0.8027978053092957\n",
      "0.8049301512241364\n",
      "0.8070019974708557\n",
      "0.8090192818641663\n",
      "0.8111659340858459\n",
      "0.8132725555896759\n",
      "0.8153678419589996\n",
      "0.8174121918678283\n",
      "0.8195320379734039\n",
      "0.8216605410575867\n",
      "0.8238054769039154\n",
      "0.8258705253601074\n",
      "0.8279384572505951\n",
      "0.8300439722537994\n",
      "0.8321805300712586\n",
      "0.8341999027729035\n",
      "0.8362957777976989\n",
      "0.8384183514118194\n",
      "0.8404552001953125\n",
      "0.8424048309326172\n",
      "0.8444613156318664\n",
      "0.8465648846626281\n",
      "0.848683913230896\n",
      "0.8507578859329223\n",
      "0.8529272186756134\n",
      "0.8549777772426606\n",
      "0.857102956533432\n",
      "0.8592549440860748\n",
      "0.8612690782546997\n",
      "0.8633074746131897\n",
      "0.8653538854122161\n",
      "0.86747594165802\n",
      "0.8695411343574524\n",
      "0.8715674178600311\n",
      "0.8736689462661743\n",
      "0.8757758777141571\n",
      "0.8778484406471252\n",
      "0.8798798751831055\n",
      "0.881978259563446\n",
      "0.8840503613948822\n",
      "0.8861496448516846\n",
      "0.8881939346790314\n",
      "0.8902867252826691\n",
      "0.8924397146701812\n",
      "0.8945303583145141\n",
      "0.8966728076934815\n",
      "0.8987819671630859\n",
      "0.9007791661024094\n",
      "0.9028693763017654\n",
      "0.9049400273561478\n",
      "0.9071537438631058\n",
      "0.9092950292825699\n",
      "0.9114256325960159\n",
      "0.9135168286561965\n",
      "0.9155487276315689\n",
      "0.9176562448740005\n",
      "0.9197458947896957\n",
      "0.9217955654859543\n",
      "0.9239061950445175\n",
      "0.9259601517915725\n",
      "0.9279912613630295\n",
      "0.9299921382665635\n",
      "0.932075285077095\n",
      "0.9339725306034088\n",
      "0.9361382060050965\n",
      "0.9382097785472869\n",
      "0.9403420112133026\n",
      "0.9423450214862823\n",
      "0.9444547393321991\n",
      "0.9465969161987304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486809096336365\n",
      "0.9508187093734741\n",
      "0.9529037706851959\n",
      "0.9550115625858306\n",
      "0.9570882275104523\n",
      "0.9592381246089935\n",
      "0.9612578127384186\n",
      "0.9632695183753968\n",
      "0.965343367099762\n",
      "0.967434451341629\n",
      "0.9694811601638794\n",
      "0.97156476187706\n",
      "0.9735809717178344\n",
      "0.9757445404529571\n",
      "0.9777745027542114\n",
      "0.980048490524292\n",
      "0.9820066120624542\n",
      "0.9840441815853119\n",
      "0.9861821403503418\n",
      "0.9883064606189728\n",
      "0.9903282001018524\n",
      "0.9923498618602753\n",
      "0.9944128003120423\n",
      "0.9964936037063599\n",
      "0.9984988012313842\n",
      "1.0006236760616303\n",
      "1.0026159377098083\n",
      "1.0047737848758698\n",
      "1.0068028984069823\n",
      "1.008828690290451\n",
      "1.0109224760532378\n",
      "1.0130199120044707\n",
      "1.0150911285877229\n",
      "1.0172363495826722\n",
      "1.0192167750597\n",
      "1.0212259353399278\n",
      "1.0232088717222214\n",
      "1.0252806743383407\n",
      "1.0273194142580033\n",
      "1.0293394743204116\n",
      "1.0312619194984436\n",
      "1.033371490240097\n",
      "1.0353779325485228\n",
      "1.0375617234706878\n",
      "1.0394621934890746\n",
      "1.0416203577518464\n",
      "1.0435734689235687\n",
      "1.0455430117845534\n",
      "1.0474827569723129\n",
      "1.049435175538063\n",
      "1.05138824737072\n",
      "1.053370504617691\n",
      "1.055428403377533\n",
      "1.0575128147602082\n",
      "1.0595357916355133\n",
      "1.0616535906791686\n",
      "1.063580554008484\n",
      "1.0657470393180848\n",
      "1.0677355931997299\n",
      "1.0697479156255723\n",
      "1.0717956606149674\n",
      "1.0739235388040542\n",
      "1.0759707170724868\n",
      "1.0780550915002822\n",
      "1.0801059552431107\n",
      "1.082184379696846\n",
      "1.084099388241768\n",
      "1.0861309529542924\n",
      "1.0881326225996018\n",
      "1.0901110376119614\n",
      "1.0919810545444488\n",
      "1.0940572621822358\n",
      "1.0959297376871109\n",
      "1.0978653286695481\n",
      "1.099891656279564\n",
      "1.101975632071495\n",
      "1.1039696527719498\n",
      "1.1060880130529405\n",
      "1.1081893326044083\n",
      "1.1103282562494279\n",
      "1.1123899492025375\n",
      "1.1144551857709886\n",
      "1.1163723483085632\n",
      "1.1183724908828736\n",
      "1.1204156939983367\n",
      "1.1224878561496734\n",
      "1.1244062544107438\n",
      "1.126260838031769\n",
      "1.128221414923668\n",
      "1.130295884490013\n",
      "1.1322071928977966\n",
      "1.1342376608848572\n",
      "1.1361442650556564\n",
      "1.1381960493326186\n",
      "1.1401218866109848\n",
      "1.1421540511846542\n",
      "1.1441993299722673\n",
      "1.1461828275918962\n",
      "1.1481866856813432\n",
      "1.1502679892778396\n",
      "1.1522030074596405\n",
      "1.154210398197174\n",
      "1.156202566385269\n",
      "1.1582036190032958\n",
      "1.160187972664833\n",
      "1.1623765383958817\n",
      "1.1643817030191421\n",
      "1.1663013385534287\n",
      "1.1682722798585892\n",
      "1.170337237715721\n",
      "1.17235416162014\n",
      "1.1743519830703735\n",
      "1.176344473361969\n",
      "1.1783314331769943\n",
      "1.1802953733205794\n",
      "1.1822826789617538\n",
      "1.1841842777729035\n",
      "1.1862113292217256\n",
      "1.1881824250221253\n",
      "1.1901638493537903\n",
      "1.1920683922767639\n",
      "1.194002323627472\n",
      "1.1960212094783782\n",
      "1.1980653970241546\n",
      "1.2000592710971831\n",
      "1.2019216685295104\n",
      "1.2038589987754822\n",
      "1.205810841202736\n",
      "1.2077768565416336\n",
      "1.2097580822706222\n",
      "1.2118091415166854\n",
      "1.213860278725624\n",
      "1.2159347633123399\n",
      "1.2177979503870011\n",
      "1.2197569807767867\n",
      "1.221729400753975\n",
      "1.2237462123632432\n",
      "1.2257440980672836\n",
      "1.227650069832802\n",
      "1.229533130645752\n",
      "1.2314683043956756\n",
      "1.2333886709213258\n",
      "1.2353759317398072\n",
      "1.237334958076477\n",
      "1.239319172501564\n",
      "1.2413969501256943\n",
      "1.2436129413843156\n",
      "1.24552700984478\n",
      "1.247488242983818\n",
      "1.2494303784370422\n",
      "1.2514693500995635\n",
      "1.2534099676609038\n",
      "1.2552865731716156\n",
      "1.2572352344989777\n",
      "1.2592073401212693\n",
      "1.2613106142282486\n",
      "1.2631771553754807\n",
      "1.265161479473114\n",
      "1.2672332751750945\n",
      "1.269204092144966\n",
      "1.271175644159317\n",
      "1.273111850976944\n",
      "1.2750526056289673\n",
      "1.2769356427192688\n",
      "1.2789840519428253\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9124\\633216221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_image_num_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        outputs = net(inputs) #input is feed to neural network\n",
    "        loss = criterion(outputs, labels) #crossentropy\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        print(running_loss/1000)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076da616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab498c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
